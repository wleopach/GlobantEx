<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: INT: Co-Robot Controllers for Human-Like Physical Interaction and Improved Motor Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>1499013.00</AwardTotalIntnAmount>
<AwardAmount>1499013</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Goldberg</SignBlockName>
<PO_EMAI>lgoldber@nsf.gov</PO_EMAI>
<PO_PHON>7032928339</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Human-like robots, which perform shared tasks with humans in common workspaces, have increased application in home and office services, in rehabilitation and skill training, and in capability enhancement. Digital technologies have enabled these ubiquitous robots with easier and faster human-like audio-visual interactions. However, the lack of physical interaction has posed a significant barrier to human-robot shared tasks, which is essential in applications that require complex physical interactions during the shared tasks. A great number of studies on physical interaction between human dyads or pairs have been conducted during the past decade. Several studies showed that dyadic physical interaction improves the performance of two individuals working together on shared tasks compared to working alone. Amazingly, results showed that human dyads not only perform better, but also learn new tasks faster. Therefore, understanding how human dyads physically interact can be applied while provide insight in developing human-like robots, which to mimic human behavior when performing shared tasks with other humans or robots. The vision of this work is to understand the underlying mechanisms of human dyadic physical interaction that lead to improvement in motor performances and learning rates, and to integrate this knowledge in developing new robotic controllers. Additionally, the infrastructure of the controller and findings will be shared as open source, and educational programs will be developed to support the advancement of the field. &lt;br/&gt;&lt;br/&gt;There are many factors that define the physical interaction between dyads, such as the interactive behavior (i.e., collaboration, competition, cooperation), haptic connection (i.e., impedance levels), and skill levels of the dyads (i.e., novice-novice and expert-novice). Therefore, a systematic approach that can quantitatively compare each condition is crucial. To realize the vision of this work, a novel exoskeleton-based dyadic interaction infrastructure will be implemented to study physical dyadic interaction with multiple DOF and multiple contact points by providing virtual connections of varying and controllable impedance between the exoskeleton systems. This infrastructure will be utilized to reveal comprehensive knowledge of how the task performance and motor learning of peers in dyadic haptic interaction are affected by 1) physical interactive behaviors, 2) impedance of the multi-joint virtual connection, and 3) the skill level of peers. Then, new human-like controllers, namely, co3-robot controllers where the suffix co3 refers to robots endowed with collaborative, competitive, and cooperative human-like interactive motor behaviors, will be synthesized based on a force-impedance adaptation model and a neural network feedback error learning model of interacting peers. Finally, the co3-robot controller will be implemented to a lower limb exoskeleton and will be validated by passing a haptic Turing test, showing that the controller is indistinguishable from a human partner during dyadic physical interactions. As a result of this research, this work has the potential to enhance existing tools and devices with a haptic communication modality, thus supporting joint physical action between humans and robots.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/26/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/13/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2024488</AwardID>
<Investigator>
<FirstName>Jose</FirstName>
<LastName>Pons</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jose Pons</PI_FULL_NAME>
<EmailAddress>jose.pons@csic.es</EmailAddress>
<PI_PHON>8443552253</PI_PHON>
<NSF_ID>000681985</NSF_ID>
<StartDate>08/26/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rehabilitation Institute of Chicago</Name>
<CityName>Chicago</CityName>
<CountyName>COOK</CountyName>
<ZipCode>606113167</ZipCode>
<PhoneNumber>3122385195</PhoneNumber>
<StreetAddress>355 East Erie Street</StreetAddress>
<StreetAddress2><![CDATA[ATTN: Research Administration]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>068477546</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>REHABILITATION INSTITUTE OF CHICAGO</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>068477546</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rehabilitation Institute of Chicago]]></Name>
<CityName>Chicago</CityName>
<CountyName>COOK</CountyName>
<StateCode>IL</StateCode>
<ZipCode>606113167</ZipCode>
<StreetAddress><![CDATA[355 E. Erie St]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~1499013</FUND_OBLG>
</Award>
</rootTag>
