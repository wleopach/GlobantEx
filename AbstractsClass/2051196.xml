<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Evaluating the Impacts of Machine Learning Algorithms on Human Decisions</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2021</AwardEffectiveDate>
<AwardExpirationDate>06/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>330000.00</AwardTotalIntnAmount>
<AwardAmount>330000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04050000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>SES</Abbreviation>
<LongName>Divn Of Social and Economic Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Cheryl Eavey</SignBlockName>
<PO_EMAI>ceavey@nsf.gov</PO_EMAI>
<PO_PHON>7032927269</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This research project will develop a methodological framework and set of tools for experimentally evaluating the impacts of machine learning algorithms on human decisions. In today's data-driven society, decisions often are based at least in part on algorithmic recommendations. Whenever choosing movies to watch or shopping for clothes to wear, online sites are constantly feeding consumers with such information. The project will develop methodologies to evaluate whether algorithmic recommendations help human decision makers achieve their goals and how they affect the fairness of such decisions. The new methodologies will help researchers empirically evaluate the efficacy of algorithm-assisted human decision making in a wide range of settings. These settings include individual decisions such as online shopping as well as decisions in medicine, finance, and judicial systems that have the potential to affect the lives of many in society. The investigators will apply the new methods to a randomized evaluation of pretrial risk assessment instruments on judicial decisions. An open-source software package will be developed, and the databases used in this research will be made publicly available.&lt;br/&gt;&lt;br/&gt;This project will develop tools for experimentally evaluating whether algorithmic recommendations help human decision makers achieve their goals and how such recommendations affect the fairness of such decisions. On the methodological front, the project will show how to evaluate the impacts of machine learning algorithms on the accuracy and fairness of human decisions. Although there exists a growing literature on algorithmic fairness, existing research almost exclusively focuses on the evaluation of accuracy and fairness of the algorithms themselves. Machines and humans have their own biases, however, and these biases may interact in unexpected ways to influence ultimate decisions. Also, the existing definitions of fairness do not account for the fact that decisions may influence individuals. The methodological framework to be developed will address these open problems. On the substantive front, the project will analyze data on original, real-world randomized controlled trials (RCTs) in collaboration with several jurisdictions in the United States. The project will analyze these RCTs to evaluate the impacts of pretrial risk assessment instruments (PRAIs) on judicial decisions. There has been a growing concern in the academic and public-policy communities about the potential racial bias of these PRAIs. This research will develop and implement rigorous evaluation methodologies to answer policy-relevant questions so that direct contributions can be made to this important public policy debate.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/24/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/24/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2051196</AwardID>
<Investigator>
<FirstName>Kosuke</FirstName>
<LastName>Imai</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kosuke Imai</PI_FULL_NAME>
<EmailAddress>imai@harvard.edu</EmailAddress>
<PI_PHON>6173846778</PI_PHON>
<NSF_ID>000319058</NSF_ID>
<StartDate>05/24/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>James</FirstName>
<LastName>Greiner</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James Greiner</PI_FULL_NAME>
<EmailAddress>jgreiner@law.harvard.edu</EmailAddress>
<PI_PHON>6174955501</PI_PHON>
<NSF_ID>000646622</NSF_ID>
<StartDate>05/24/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Zhichao</FirstName>
<LastName>Jiang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Zhichao Jiang</PI_FULL_NAME>
<EmailAddress>zhichaojiang@umass.edu</EmailAddress>
<PI_PHON>4135454603</PI_PHON>
<NSF_ID>000836090</NSF_ID>
<StartDate>05/24/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Harvard University</Name>
<CityName>Cambridge</CityName>
<ZipCode>021385369</ZipCode>
<PhoneNumber>6174955501</PhoneNumber>
<StreetAddress>1033 MASSACHUSETTS AVE</StreetAddress>
<StreetAddress2><![CDATA[5th Floor]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>082359691</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>PRESIDENT AND FELLOWS OF HARVARD COLLEGE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001963263</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Harvard University]]></Name>
<CityName>CAMBRIDGE</CityName>
<StateCode>MA</StateCode>
<ZipCode>021383016</ZipCode>
<StreetAddress><![CDATA[1737 Cambridge Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>128Y</Code>
<Text>Law &amp; Science</Text>
</ProgramElement>
<ProgramElement>
<Code>1333</Code>
<Text>Methodology, Measuremt &amp; Stats</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~330000</FUND_OBLG>
</Award>
</rootTag>
