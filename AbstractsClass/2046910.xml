<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Spatial Awareness for Machine Perception</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2026</AwardExpirationDate>
<AwardTotalIntnAmount>550000.00</AwardTotalIntnAmount>
<AwardAmount>133926</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>For many applications in health, security, and robotics, the capability for computers to track objects in video is critical. From autonomous vehicles that reliably avoid obstacles to security cameras that swiftly respond during emergencies, artificial perception systems need to remain accurate during poor visibility situations, such as with cluttered rooms, dark streets, or occluded objects. This integrated research and education project aims to develop machines that are able to spatially sense their visual surroundings, even when the surroundings have low visibility with significant obstructions. On multiple levels, the investigators will furthermore use their integrated approach to advance education in artificial intelligence, such as outreach activities for K-12 students and streamlined curriculums for both undergraduate and graduate education in computer vision.&lt;br/&gt;&lt;br/&gt;The research program introduces a framework that tightly integrates geometry, motion, and acoustics in order to learn rich spatial representations of natural scenes from unlabeled visual data. The research team will study how learning from the incidental structures of unlabeled videos will cause rich spatial representations to emerge without human supervision. The framework will leverage the propagation of sound through objects to learn visual tracking under occlusion. In other cases, the project will use scene geometry to transfer incidental supervision between camera views in order to learn spatial memory models. A key advantage of the approach is the efficiency to operate on videos that span both large physical spaces and long temporal horizons. Motivated by implicit surfaces in mathematics and graphics, the algorithm will analytically represents videos as continuous functions, which are compact and robustly embed video dynamics in 3D space.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/10/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2046910</AwardID>
<Investigator>
<FirstName>Carl</FirstName>
<LastName>Vondrick</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Carl M Vondrick</PI_FULL_NAME>
<EmailAddress>cv2428@columbia.edu</EmailAddress>
<PI_PHON>2128546851</PI_PHON>
<NSF_ID>000755733</NSF_ID>
<StartDate>03/10/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Columbia University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100276902</ZipCode>
<PhoneNumber>2128546851</PhoneNumber>
<StreetAddress>2960 Broadway</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>049179401</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>049179401</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Columbia University]]></Name>
<CityName>New York</CityName>
<StateCode>NY</StateCode>
<ZipCode>100276624</ZipCode>
<StreetAddress><![CDATA[2960 Broadway]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY10</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~133926</FUND_OBLG>
</Award>
</rootTag>
