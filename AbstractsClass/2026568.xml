<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>FW-HTF-RM Collaborative Research: Augmenting Remote Medical Procedure Training and Assistance with Spatial Computing and Volumetric Capture</AwardTitle>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>897306.00</AwardTotalIntnAmount>
<AwardAmount>897306</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>11090000</Code>
<Directorate>
<Abbreviation>EHR</Abbreviation>
<LongName>Direct For Education and Human Resources</LongName>
</Directorate>
<Division>
<Abbreviation>DRL</Abbreviation>
<LongName>Division Of Research On Learning</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Chia Shen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Healthcare expenditure accounts for 17% of the US Gross Domestic Product and 12% of the workforce, but access to highly skilled health professionals is not evenly distributed across geographic and socioeconomic strata.  Videoconferencing-based telehealth systems partly address this inequality by enabling experts to assist and train remote or rural medical personnel. However, videoconferencing alone cannot adequately convey three-dimensional information that is essential in performing many medical procedures. For example, it is very difficult for an expert to precisely guide an operator's hand remotely in performing a medical procedure using only videoconferencing. This project will transform the way medical personnel communicates and collaborates across the distance by allowing for real-time exchange of three-dimensional information that is missing in current videoconferencing telehealth. The project will lead to more equitable access to healthcare; improved success for medical procedures that require the assistance of a remote expert; more cost-effective distribution of healthcare skills and training; and higher quality expert medical advice from a distance. It will also engage students in interdisciplinary research using emerging technology.&lt;br/&gt;&lt;br/&gt;The goals of this research include: i)  developing an understanding of the communication needs  for medical staff in distant  training, mentoring and procedural assistance, ii) insights into the application of mixed-reality volumetric representation and transmission in remote healthcare settings; iii) design guidelines for a mixed-reality volumetric communication system that simulates the physical presence of the patient at the location of the remote expert; iv) clinical evaluation of the utility of 3D spatial information in remote medical procedures assistance; and v) user studies examining the efficacy of spatially-enhanced communication in remote medical training and guidance.  The project aims to enroll 144 trainees consisting of medical and allied health students, physicians, physician assistants, and nurse practitioners to participate in randomized training experiments in three conditions: current standard training, 2D and voice guidance, and 3D mixed-reality. To achieve the above goals, researchers will also advance spatial computation and volumetric capture technologies. The project deliverables include a prototype of a spatial communication telehealth system that will create a real-time three-dimensional representation of the patient. This shared representation will be annotated with information exchanged between the medical procedure operator and the remotely guiding expert. The project is a collaboration between the Department of Emergency Medicine and the Clinical Learning and Simulation Skills Center at George Washington University, and American University. The multidisciplinary research team includes researchers from computer science, human-computer interaction, communication, telehealth, emergency medicine, medical simulation, and medical education.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/06/2020</MinAmdLetterDate>
<MaxAmdLetterDate>08/06/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2026568</AwardID>
<Investigator>
<FirstName>Neal</FirstName>
<LastName>Sikka</LastName>
<EmailAddress>nsikka@mfa.gwu.edu</EmailAddress>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Colton</FirstName>
<LastName>Hood</LastName>
<EmailAddress>chood@mfa.gwu.edu</EmailAddress>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Rutenberg</LastName>
<EmailAddress>arutenberg@mfa.gwu.edu</EmailAddress>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Claudia</FirstName>
<LastName>Ranniger</LastName>
<EmailAddress>ranniger@gwu.edu</EmailAddress>
<StartDate>08/06/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>George Washington University</Name>
<CityName>Washington</CityName>
<ZipCode>200520086</ZipCode>
<PhoneNumber>2029940728</PhoneNumber>
<StreetAddress>1922 F Street NW</StreetAddress>
<CountryName>United States</CountryName>
<StateName>District of Columbia</StateName>
<StateCode>DC</StateCode>
</Institution>
<ProgramElement>
<Code>103Y</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramReference>
</Award>
</rootTag>
