<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>I-Corps:  Determining occupant load and location through machine vision with on-device image processing</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2021</AwardEffectiveDate>
<AwardExpirationDate>07/31/2022</AwardExpirationDate>
<AwardTotalIntnAmount>50000.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ruth Shuman</SignBlockName>
<PO_EMAI>rshuman@nsf.gov</PO_EMAI>
<PO_PHON>7032922160</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this I-Corps project is the development of smart cameras with on-board processing. The proposed technology will be used as a part of building and smart city management systems. Building heating, ventilation and air conditioning (HVAC) accounts for 13% of all energy usage in the United States and nearly 40% of buildings' energy. Accurate occupancy detection may reduce energy use in HVAC systems by as much as 30%. However, there are concerns regarding occupancy detection when assessing accurate detection and privacy. The proposed technology may solve these concerns by relying on the camera's vision to provide precise information and on-device analysis to ensure no image privacy data is transmitted.  The proposed technology also may be used to improve traffic light planning. Pedestrians congregating at an intersection may cause safety issues for vehicles and people. The proposed technology allows for the counting of people, cars, and bikes and the integration of this information. Additional analysis may be performed by providing count data and if pedestrian counts are not changing, there may be a need to modify traffic patterns or alert first responders.&lt;br/&gt;&lt;br/&gt;This I-Corps project is based on the development of embedded devices to run object-detection algorithms.  Object detection using deep neural networks (DNNs) involves a large amount of computation, which impedes its implementation on resource/energy-limited, user-end devices. The reason for the success of DNNs is due to having knowledge over different domains of observed environments. However, only a limited knowledge of the observed environment at inference time is required, which may be learned using a shallow neural network (SHNN). The TKD (Temporal Knowledge Distillation) is a system-level design that is proposed to improve the energy consumption of object detection on the user-end device. An SHNN is deployed on the user-end device to detect objects in the observing environment. Also, a knowledge transfer mechanism is implemented to update the SHNN model using the DNN knowledge when there is a change in the object domain. Experiments demonstrate that the user-end device's energy consumption and the inference time can be improved by 78% and 71% compared with running the deep model on the user-end device.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/24/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/21/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2054807</AwardID>
<Investigator>
<FirstName>Yezhou</FirstName>
<LastName>Yang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yezhou Yang</PI_FULL_NAME>
<EmailAddress>yz.yang@asu.edu</EmailAddress>
<PI_PHON>4809655479</PI_PHON>
<NSF_ID>000733585</NSF_ID>
<StartDate>02/24/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<StreetAddress2><![CDATA[660 South Mill Avenue, Suite 310]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>AZ09</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>943360412</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>ARIZONA STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>806345658</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Arizona State University]]></Name>
<CityName>Tempe</CityName>
<StateCode>AZ</StateCode>
<ZipCode>852816011</ZipCode>
<StreetAddress><![CDATA[P.O. Box 876011]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>09</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>AZ09</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8023</Code>
<Text>I-Corps</Text>
</ProgramElement>
<ProgramReference>
<Code>7453</Code>
<Text>GRAPHICS &amp; VISUALIZATION</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~50000</FUND_OBLG>
</Award>
</rootTag>
