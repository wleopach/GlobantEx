<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Learning from Demonstration for Customer-Grade Robots</AwardTitle>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2021</AwardExpirationDate>
<AwardTotalIntnAmount>224999.00</AwardTotalIntnAmount>
<AwardAmount>224999</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>IIP</Abbreviation>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The broader impact of this Small Business Innovation Research (SBIR) Phase I project is to advance the capability of current robots to autonomously engage with the household environment, recognize objects, and manipulate them in a purposeful way. The proposed methodology adds this capability to a wide range of household and entertainment robots. A user can teach a robot a wide range of autonomous behaviors out of reach of the previously installed baseline software packages. The proposed technology radically lowers the threshold for teaching a robot sophisticated behaviors without complex programming nor high-quality demonstrations. This enables a class of new applications beyond the simple repetition of industrial activities. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project leverages a deep neural network-based computer vision system that creates a lower-dimensional representation of the world-view of the robot. On this latent encoding, the robot behavior is trained using a combination of optimization criteria (e.g. training loss) that ensures the generalization of the target task, smooth operation, recovery from accidental mistakes, and ability to choose between alternative solutions to the problem (e.g. avoid an obstacle to the left or to the right). The technology is novel: current learning by demonstration systems usually reproduce an identical trajectory to what has been demonstrated. This might be useful on a factory floor but would not work in a home environment. In contrast, the proposed model learns a generalizable behavior that uses demonstrations to obtain clues as to how to solve a particular manipulation problem and can both identify and learn from its own mistakes.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/06/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/06/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2001995</AwardID>
<Investigator>
<FirstName>Rouhollah</FirstName>
<LastName>Rahmatizadeh</LastName>
<EmailAddress>rouhollah@ximpatico.com</EmailAddress>
<StartDate>07/06/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>XIMPATICO INC.</Name>
<CityName>SAN JOSE</CityName>
<ZipCode>951342869</ZipCode>
<PhoneNumber>4074095859</PhoneNumber>
<StreetAddress>680 EPIC WAY APT 354</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SBIR Phase I</Text>
</ProgramElement>
<ProgramReference>
<Code>8033</Code>
<Text>Hardware Software Integration</Text>
</ProgramReference>
</Award>
</rootTag>
