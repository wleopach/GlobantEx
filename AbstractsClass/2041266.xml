<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral dissertation research: Evoked Category Representations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/01/2021</AwardEffectiveDate>
<AwardExpirationDate>02/28/2023</AwardExpirationDate>
<AwardTotalIntnAmount>19200.00</AwardTotalIntnAmount>
<AwardAmount>19200</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Joan Maling</SignBlockName>
<PO_EMAI>jmaling@nsf.gov</PO_EMAI>
<PO_PHON>7032928046</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Humans understand speech by mapping fine-grained acoustic details to phonemes – the smallest units used to distinguish words – stored in long-term memory. A fundamental issue regarding this process is the nature of the phoneme. In classical generative phonology, a phoneme is a combination of abstract and discretized features, devoid of acoustic details. On this view, speech perception is a process of sorting gradient information into non-gradient categories. However, evidence has emerged that speakers are sensitive to minute and gradient acoustic properties of speech sounds when making decisions about what they hear, which suggests that the phoneme itself may encapsulate acoustic details and their probability distributions that can be reshaped by speakers’ experience. This view assumes a more direct relationship between the speech sound and the phoneme.  The current project will conduct experiments measuring brain activity designed to test the predictions of both models, facilitating an understanding of this core mechanism in speech perception.&lt;br/&gt;&lt;br/&gt;The experimental methodology utilizes event-related brain potentials which measure automatic sound change detection in auditory cortex via oddball paradigms. One experiment will compare a category to a token from the same category: here, a change detection response will require that the category encodes physical stimulus properties. A second experiment will manipulate two different statistical distributions of the tokens that lead to a category representation. If the oddball response is modulated by the statistical information in the stimuli that gave rise to the "temporary" category, then the brain must be able to encode this information in category representations. If no sensitivity to acoustics or statistics is observed, then it must be the case that phoneme category representations do not contain gradient acoustic information. The findings can potentially increase the understanding of how categories are formed in human cognition.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/24/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2041266</AwardID>
<Investigator>
<FirstName>Arild</FirstName>
<LastName>Hestvik</LastName>
<PI_MID_INIT>G</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Arild G Hestvik</PI_FULL_NAME>
<EmailAddress>hestvik@udel.edu</EmailAddress>
<PI_PHON>3028316089</PI_PHON>
<NSF_ID>000534777</NSF_ID>
<StartDate>02/24/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Chao</FirstName>
<LastName>Han</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Chao Han</PI_FULL_NAME>
<EmailAddress>hanchao@udel.edu</EmailAddress>
<PI_PHON>3025136281</PI_PHON>
<NSF_ID>000818299</NSF_ID>
<StartDate>02/24/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Delaware</Name>
<CityName>Newark</CityName>
<ZipCode>197160099</ZipCode>
<PhoneNumber>3028312136</PhoneNumber>
<StreetAddress>210 Hullihen Hall</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<StateCode>DE</StateCode>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>DE00</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>059007500</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF DELAWARE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>059007500</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Delaware,Dept of Linguistics and Cognitive Science]]></Name>
<CityName>Newark</CityName>
<StateCode>DE</StateCode>
<ZipCode>197160099</ZipCode>
<StreetAddress><![CDATA[125 East Main Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Delaware</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>00</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>DE00</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>8374</Code>
<Text>DDRI Linguistics</Text>
</ProgramElement>
<ProgramReference>
<Code>1311</Code>
<Text>LINGUISTICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~19200</FUND_OBLG>
</Award>
</rootTag>
