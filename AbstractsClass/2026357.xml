<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>FW-HTF-RM: Collaborative Research: Assistive Intelligence for Cooperative Robot and Inspector Survey of Infrastructure Systems (AI-CRISIS)</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>807747.00</AwardTotalIntnAmount>
<AwardAmount>807747</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ruyan Guo</SignBlockName>
<PO_EMAI>rguo@nsf.gov</PO_EMAI>
<PO_PHON>7032927718</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The U.S. civil infrastructure faces the prospect of rapid future deterioration. For example, 39% of the over 600,000 highway bridges in the U.S. have exceeded their design life of 50 years. To ensure the safety and welfare of citizens, state Departments of Transportation are required to inspect bridges every two years. To make inspection and reporting objective and consistent, robots such as unmanned aerial vehicles have recently been introduced to perform autonomous surveys of bridges. These robots, equipped with cameras, will rapidly provide a large set of survey data that can be used to aid inspectors in assessing the condition of bridges. To transform these multidisciplinary topics into a new integrated bridge inspection capability, this multi-university team will develop and implement a cooperative robot-inspector system with assistive intelligence (AI) in order to make the future bridge inspection significantly faster, cheaper, safer, and more consistent. A robotic platform equipped with infrared cameras and a central processing unit with intelligent algorithms will operate in both flying and crawling modes, travel in proximity to various parts/elements of a bridge, and collect high-fidelity images of the entire bridge. Inspectors will be instrumented and monitored with a suite of wearable sensors to enable optimal robot-inspector cooperation during each bridge inspection. AI algorithms will be developed in modules to analyze the big data from human sensors and cameras in support of the pre-inspection workforce training, during-inspection element defect detection, and post-inspection condition evaluation of bridges. The robot-inspector-AI system will be integrated and validated at six bridge sites in collaboration with stakeholders.&lt;br/&gt;&lt;br/&gt;This multidisciplinary project aims to explore and develop the scientific knowledge and underling methods of AI for a cooperative inspector-robot survey of bridges. The scope of work includes: (1) to develop an optimal screening-to-probing inspection strategy using fast and accurate detection of both surface and internal defects in reinforced concrete slabs (representative bridge elements) from active thermal and visible light imaging; (2) to create a causal model of inspectors’ task performance to support an optimal job design, effective training, and onsite operation; (3) to develop adaptive AI algorithms with human inspectors in the loop for a rapid adaptation to future work contexts, and efficient and reliable data analyses; and (4) to enable a spatial correlation among the elements of an entire bridge with a maximum use of domain expertise, and thus improve the effectiveness and applicability of adaptive AI. The methods and technologies developed in this study will be transferred into the hands of stakeholders, researchers, policy makers, and end users (bridge inspectors) through publications, presentations, field demonstrations, and training. In particular, the world’s first bridge benchmark dataset of videos, labeled objects, and metadata established from real-world bridges, upon approval by stakeholders, will be shared with the international community via an AI-enabled bridge inspection competition.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/17/2020</MinAmdLetterDate>
<MaxAmdLetterDate>11/24/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2026357</AwardID>
<Investigator>
<FirstName>Genda</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Genda Chen</PI_FULL_NAME>
<EmailAddress>gchen@mst.edu</EmailAddress>
<PI_PHON>5733414462</PI_PHON>
<NSF_ID>000148267</NSF_ID>
<StartDate>08/17/2020</StartDate>
<EndDate>08/26/2020</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Genda</FirstName>
<LastName>Chen</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Genda Chen</PI_FULL_NAME>
<EmailAddress>gchen@mst.edu</EmailAddress>
<PI_PHON>5733414462</PI_PHON>
<NSF_ID>000148267</NSF_ID>
<StartDate>08/26/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ruwen</FirstName>
<LastName>Qin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ruwen Qin</PI_FULL_NAME>
<EmailAddress>ruwen.qin@stonybrook.edu</EmailAddress>
<PI_PHON>6316329341</PI_PHON>
<NSF_ID>000513600</NSF_ID>
<StartDate>08/17/2020</StartDate>
<EndDate>08/26/2020</EndDate>
<RoleCode>Former Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ruwen</FirstName>
<LastName>Qin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ruwen Qin</PI_FULL_NAME>
<EmailAddress>ruwen.qin@stonybrook.edu</EmailAddress>
<PI_PHON>6316329341</PI_PHON>
<NSF_ID>000513600</NSF_ID>
<StartDate>08/26/2020</StartDate>
<EndDate>11/24/2020</EndDate>
<RoleCode>Former Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Missouri University of Science and Technology</Name>
<CityName>Rolla</CityName>
<CountyName/>
<ZipCode>654096506</ZipCode>
<PhoneNumber>5733414134</PhoneNumber>
<StreetAddress>300 W 12th Street</StreetAddress>
<StreetAddress2><![CDATA[202 Centennial Hall]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<StateCode>MO</StateCode>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MO08</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>804883767</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF MISSOURI SYSTEM</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>006326904</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Missouri University of Science and Technology]]></Name>
<CityName>Rolla</CityName>
<CountyName/>
<StateCode>MO</StateCode>
<ZipCode>654096506</ZipCode>
<StreetAddress><![CDATA[300 W 12th Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Missouri</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>08</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MO08</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>103Y</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>FW-HTF Futr Wrk Hum-Tech Frntr</Text>
</ProgramReference>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>8028</Code>
<Text>Sensor Technology</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~807747</FUND_OBLG>
</Award>
</rootTag>
