<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Learning Methods for Decentralized Control in Multi-Agent Systems</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2020</AwardEffectiveDate>
<AwardExpirationDate>08/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>400000.00</AwardTotalIntnAmount>
<AwardAmount>400000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Donald Wunsch</SignBlockName>
<PO_EMAI>dwunsch@nsf.gov</PO_EMAI>
<PO_PHON>7032927102</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Multi-agent systems (MAS) are expected to become increasingly prevalent in military and civilian domains. Decentralized control and decision-making by agents is a fundamental driver of the diverse applications of multi-agent systems. Agents are expected to act and make decisions without relying on a centralized command structure. Communication and coordination among agents may have to be carried out over sparse, intermittent, unreliable, low data rate and/or noisy communication networks that preclude the possibility of centralized information and decision-making. A key design challenge is to find efficient ways of computing decentralized control and decision strategies for a team of agents. The problem is further compounded by various kinds of uncertainties - uncertainties about the environment, noisy observations, unreliable communication as well as uncertainties in the system model. In this project, we aim to develop learning-based methods for decentralized control in multi-agent systems. &lt;br/&gt;&lt;br/&gt;Intellectual merit: The research develops the following: (i) learning-based practical methods for computing near-optimal decentralized control policies for multi-agent systems with known system model. (ii)  online decentralized learning algorithms for control of multi-agent systems with unknown system model.  We aim to develop decentralized algorithms that asymptotically find the optimal decentralized policy for such systems and learn in the most efficient way possible. The proposed research will lay the foundations for Learning-based Decentralized Optimal Control, which is expected to become increasingly important for emerging multi-agent system applications. &lt;br/&gt; &lt;br/&gt;Broader Impact: The research will significantly impact the science of multi-agent systems, autonomous robotic systems, and reinforcement learning. It will introduce a systematic and practical learning-based approach to design of multi-agent systems that has long been lacking in the literature. The educational impact of the proposed research will include: (i) providing graduate students with a multi-disciplinary training in stochastic control, online learning and optimization, (ii) involvement of undergraduate students during summer to perform computational and lab experiments (iii) efforts to recruit female and under-represented minority students in our projects; (iv) The research results will be incorporated in classes on reinforcement learning, stochastic systems, and decentralized control taught by the principal investigators.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/27/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2025732</AwardID>
<Investigator>
<FirstName>Rahul</FirstName>
<LastName>Jain</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Rahul Jain</PI_FULL_NAME>
<EmailAddress>rahul.jain@usc.edu</EmailAddress>
<PI_PHON>2137402246</PI_PHON>
<NSF_ID>000515860</NSF_ID>
<StartDate>07/27/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ashutosh</FirstName>
<LastName>Nayyar</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ashutosh Nayyar</PI_FULL_NAME>
<EmailAddress>ashutosn@usc.edu</EmailAddress>
<PI_PHON>2137402353</PI_PHON>
<NSF_ID>000656351</NSF_ID>
<StartDate>07/27/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>Los Angeles</CityName>
<CountyName>LOS ANGELES</CountyName>
<ZipCode>900890001</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>University Park</StreetAddress>
<StreetAddress2><![CDATA[3720 S. Flower St.]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>072933393</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>072933393</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>Los Angeles</CityName>
<CountyName>LOS ANGELES</CountyName>
<StateCode>CA</StateCode>
<ZipCode>900890001</ZipCode>
<StreetAddress><![CDATA[3740 McClintock Ave]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7607</Code>
<Text>EPCN-Energy-Power-Ctrl-Netwrks</Text>
</ProgramElement>
<ProgramReference>
<Code>1653</Code>
<Text>Adaptive &amp; intelligent systems</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~400000</FUND_OBLG>
</Award>
</rootTag>
