<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: The social representation of the physical world</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>03/15/2021</AwardEffectiveDate>
<AwardExpirationDate>02/28/2026</AwardExpirationDate>
<AwardTotalIntnAmount>600000.00</AwardTotalIntnAmount>
<AwardAmount>432600</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Imagine walking into a crowded conference room, spotting an empty seat, then realizing there is a jacket on it. From this simple arrangement of objects, we might suspect that someone was using the chair, left temporarily, and intends to return. Situations where we extract social information from our physical surroundings are commonplace: we hang rope across entrances to signal people should not walk through, we mark trees to indicate hiking trails, and we leave our office doors ajar to reveal we are available. This project will use a combination of computational modeling and behavioral studies to understand how people read social signals from their physical environment. Characterizing how people extract social information from their physical surroundings is critical for understanding how humans seamlessly coordinate and cooperate with each other, even in the absence of direct communication or physical interactions. The results also have implications for the goal of instantiating human social intelligence in machines. For example, there have been remarkable advances in robot navigation, but these algorithms do not yet represent the social information in physical environments, treating them as devoid of social meaning.&lt;br/&gt;&lt;br/&gt;The proposed project will answer three questions: What aspects of the physical world contain social information for humans? How do we infer what produced this information? And how do we determine what it means? To answer these questions, the investigator will combine advances in computational models of social reasoning and computational models of physical reasoning to determine how these two cognitive systems interact with each other. Specifically, the investigator will build computational models that jointly reason about how people’s mental states lead to different behaviors and how these behaviors leave observable traces in the environment. The model’s behavior will be compared with data from human participants to determine the extent to which the model can capture and replicate human reasoning. Computational tools will be developed with the parallel goals of producing high-quality open-source libraries that are widely accessible to all students interested in computational cognitive science. Software will be complemented with extensive tutorials showing how to implement various classical models, created by the investigator in collaboration with undergraduate and graduate students.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/31/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2045778</AwardID>
<Investigator>
<FirstName>Julian</FirstName>
<LastName>Jara-Ettinger</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Julian Jara-Ettinger</PI_FULL_NAME>
<EmailAddress>julian.jara-ettinger@yale.edu</EmailAddress>
<PI_PHON>2037854689</PI_PHON>
<NSF_ID>000767869</NSF_ID>
<StartDate>03/31/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Yale University</Name>
<CityName>New Haven</CityName>
<ZipCode>065208327</ZipCode>
<PhoneNumber>2037854689</PhoneNumber>
<StreetAddress>Office of Sponsored Projects</StreetAddress>
<StreetAddress2><![CDATA[P.O. Box 208327]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<StateCode>CT</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CT03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>043207562</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>YALE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>043207562</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Yale University]]></Name>
<CityName>New Haven</CityName>
<StateCode>CT</StateCode>
<ZipCode>065208205</ZipCode>
<StreetAddress><![CDATA[2 Hilhouse Avenue]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Connecticut</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CT03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~432600</FUND_OBLG>
</Award>
</rootTag>
