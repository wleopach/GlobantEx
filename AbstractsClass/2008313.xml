<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Understanding and Synthesizing People in 3D Scenes</AwardTitle>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>498622.00</AwardTotalIntnAmount>
<AwardAmount>498622</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project advances fundamental research into understanding people in images, and how they interact with their environment. This goal is important because people are crucial in many real-world applications that involve imagery. For example, vehicles and robots should perceive people, predict their behavior, and operate safely around them. In the realm of computer graphics, algorithms that generate content for movies and games should depict people with realistic appearance and who interact with their environment in realistic ways. Developing a computational understanding of people sufficient for such applications will involve, crucially, understanding the connection between people and the scenes they inhabit. For instance, in a typical street scene, people will tend to appear walking on sidewalks or crosswalks -- but if it suddenly starts raining, they might look and act differently, for instance, by carrying umbrellas, hurrying for shelter, etc. This project seeks to build such a computational understanding of people in scenes via new human-centric methods for perceiving the world. The research will also be coupled with educational activities, including efforts to broaden participation in computing.&lt;br/&gt;&lt;br/&gt;The technical goals of the project fall into two main thrusts corresponding to a computer vision and a computer graphics goal: (1) human-centric understanding of images, and (2) realistic synthesis of people into images. Both of these goals will be driven by new machine learning methods that will answer the following series of questions: given an image of a scene, where might a person appear, what would they be doing, and how would they look? These questions are distinct from the typical computer vision task of identifying where humans actually are in an image, and instead involve reasoning about where they could be. This reasoning is highly dependent on the scene depicted in the image -- are there benches, is it raining, etc. -- and also on the 3D geometry of the scene -- e.g., whether a particular surface is horizontal or vertical. Hence, the project will explore scene- and 3D-aware learning of people and their interactions with the world.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/17/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/17/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2008313</AwardID>
<Investigator>
<FirstName>Noah</FirstName>
<LastName>Snavely</LastName>
<EmailAddress>snavely@cs.cornell.edu</EmailAddress>
<StartDate>07/17/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Cornell University</Name>
<CityName>Ithaca</CityName>
<ZipCode>148502820</ZipCode>
<PhoneNumber>6072555014</PhoneNumber>
<StreetAddress>373 Pine Tree Road</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
