<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>MLWiNS: Resource Constrained Mobile Data Analytics Assisted by the Wireless Edge</AwardTitle>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>300000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Increasing amounts of data are being collected on mobile telephones and internet-of-things (IoT) devices. Users are interested in analyzing this data to extract actionable information, for example, identifying objects of interest from high-resolution mobile phone pictures. The state-of-the-art technique for such data analysis is via deep learning which makes use of sophisticated software algorithms modeled on the functioning of the human brain. Deep learning algorithms are, however, too complex to run on small, battery constrained mobile devices. The alternative, i.e., transmitting data to the mobile base station where the deep learning algorithm can be executed on a powerful server, consumes too much bandwidth. This project seeks to devise new methods to compress data before transmission, thus reducing bandwidth costs while still allowing for the data to be analyzed at the base station. Departing from existing data compression methods optimized for reproducing the original images, the project will use deep learning itself to compress the data in a fashion that only keeps the critical parts of data necessary for subsequent analysis. The resulting deep learning based compression algorithms will be simple enough to run on mobile devices while drastically reducing the amount of data that needs to be transmitted to mobile base stations for analysis, without significantly compromising the analysis performance. The proposed research will provide greater capability and functionality to mobile device users, enable extended battery lifetimes, and more efficient sharing of the wireless spectrum for analytics tasks. The project also envisions a multi-pronged effort aimed at outreach to communities of interest, educating and training the next generation of machine learning and wireless professionals at the K-12, undergraduate and graduate levels, and broadening participation of under-represented minority groups.&lt;br/&gt;&lt;br/&gt;The project seeks to learn ?analytics-aware? compression schemes from data by training low-complexity compressor deep neural networks (DNNs) that execute on mobile devices and achieve a range of transmission rate and analytics accuracy targets. As a first step, efficient DNN pruning techniques will be developed to minimize the DNN complexity, while maintaining the rate-accuracy efficiency for one or a collection of analytics tasks. Next, to efficiently adapt to varying wireless channel conditions, the project will seek to design adaptive DNN architectures that can operate at variable transmission rates and computational complexities. For instance, when the wireless channel quality drops, the proposed compression scheme will be able to quickly reduce transmission rate in response while ensuring the same analytics accuracy, but at the cost of greater computational power on the mobile device. Further, wireless channel allocation and scheduling policies that leverage the proposed adaptive DNN architectures will be developed to optimize the overall analytics accuracy at the server. The benefits of the proposed approach in terms of total battery life savings for the mobile device will be demonstrated using detailed simulation studies of various wireless protocols including those used for LTE (Long Term Evolution) and mmWave channels.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/24/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/24/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2003182</AwardID>
<Investigator>
<FirstName>Yao</FirstName>
<LastName>Wang</LastName>
<EmailAddress>yw523@nyu.edu</EmailAddress>
<StartDate>06/24/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Elza</FirstName>
<LastName>Erkip</LastName>
<EmailAddress>elza@nyu.edu</EmailAddress>
<StartDate>06/24/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Siddharth</FirstName>
<LastName>Garg</LastName>
<EmailAddress>sg175@nyu.edu</EmailAddress>
<StartDate>06/24/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>New York University</Name>
<CityName>NEW YORK</CityName>
<ZipCode>100121019</ZipCode>
<PhoneNumber>2129982121</PhoneNumber>
<StreetAddress>70 WASHINGTON SQUARE S</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>7484</Code>
<Text>IIS Special Projects</Text>
</ProgramElement>
<ProgramReference>
<Code>021Z</Code>
<Text>Industry Partnerships</Text>
</ProgramReference>
<ProgramReference>
<Code>8585</Code>
<Text>NSF/Intel Partnership Projects</Text>
</ProgramReference>
</Award>
</rootTag>
