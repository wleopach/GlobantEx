<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>FAI: Fairness in Machine Learning with Human in the Loop</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2021</AwardEffectiveDate>
<AwardExpirationDate>01/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>625000.00</AwardTotalIntnAmount>
<AwardAmount>625000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Todd Leen</SignBlockName>
<PO_EMAI>tleen@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Despite early successes and significant potential, algorithmic decision-making systems often inherit and encode biases that exist in the training data and/or the training process.  It is thus important to understand the consequences of deploying and using machine learning models and provide algorithmic treatments to ensure that such techniques will ultimately serve the social good. While recent works have looked into the fairness issues in AI concerning the “short-term” measures, the long-term consequences and impacts of automated decision making remain unclear. The understanding of the long-term impact of a fair decision provides guidelines to policy-makers when deploying an algorithmic model in a dynamic environment and is critical to its trustworthiness and adoption. It will also drive the design of algorithms with an eye toward the welfare of both the makers and the users of these algorithms, with an ultimate goal of achieving more equitable outcomes. &lt;br/&gt; &lt;br/&gt;This project aims to understand the long-term impact of fair decisions made by automated machine learning algorithms via establishing an analytical, algorithmic, and experimental framework that captures the sequential learning and decision process, the actions and dynamics of the underlying user population, and its welfare. This knowledge will help design the right fairness criteria and intervention mechanisms throughout the life cycle of the decision-action loop to ensure long-term equitable outcomes. Central to this project’s intellectual inquiry is the focus on human in the loop, i.e., an AI-human feedback loop with automated decision-making that involves human participation. Our focus on the long-term impacts of fair algorithmic decision-making while explicitly modeling and incorporating human agents in the loop provides a theoretically rigorous framework to understand how an algorithmic decision-maker fares in the foreseeable future.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/25/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2040800</AwardID>
<Investigator>
<FirstName>Mingyan</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Mingyan Liu</PI_FULL_NAME>
<EmailAddress>mingyan@eecs.umich.edu</EmailAddress>
<PI_PHON>7347649546</PI_PHON>
<NSF_ID>000230014</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Ming</FirstName>
<LastName>Yin</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ming Yin</PI_FULL_NAME>
<EmailAddress>mingyin@purdue.edu</EmailAddress>
<PI_PHON>6172168924</PI_PHON>
<NSF_ID>000784929</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yang</FirstName>
<LastName>Liu</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yang Liu</PI_FULL_NAME>
<EmailAddress>yangliu@ucsc.edu</EmailAddress>
<PI_PHON>7345467375</PI_PHON>
<NSF_ID>000787350</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Parinaz</FirstName>
<LastName>Naghizadeh Ardabili</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Parinaz Naghizadeh Ardabili</PI_FULL_NAME>
<EmailAddress>naghizadeh.1@osu.edu</EmailAddress>
<PI_PHON>6142471638</PI_PHON>
<NSF_ID>000818835</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Santa Cruz</Name>
<CityName>Santa Cruz</CityName>
<ZipCode>950641077</ZipCode>
<PhoneNumber>8314595278</PhoneNumber>
<StreetAddress>1156 High Street</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA20</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>125084723</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF CALIFORNIA, SANTA CRUZ</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>071549000</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of California-Santa Cruz]]></Name>
<CityName>Santa Cruz</CityName>
<StateCode>CA</StateCode>
<ZipCode>950641100</ZipCode>
<StreetAddress><![CDATA[SOE 3, UC Santa Cruz, 1156 High]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA20</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>114Y</Code>
<Text>Fairness in Artificial Intelli</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~625000</FUND_OBLG>
</Award>
</rootTag>
