<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Formal Design of Human Robot Collaboration in Safety Critical Scenarios</AwardTitle>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>499848.00</AwardTotalIntnAmount>
<AwardAmount>499848</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Todd Leen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Human-robot collaboration technologies aim to combine the strengths from humans with those of robots. Robots excel at handling repeated routines with much higher precision and speed, and longer endurance.  Humans, on the other hand, have superior perception capabilities and are much better in face of uncertainties and unexpected situations. For example, a scratch on a transparent glass can be easily detected by human eyes but presents an extremely hard challenge for computer vision. Finding principles to help design effective collaboration between humans and robots (or humans and computers in general) is core to advances in cyber-human systems. In addition, many cyber-human system applications, such as joint assembly manufacturing, driver assistance, and robot-assisted surgery are safety critical and need to achieve complex high-level tasks with guaranteed performance. This project aims to derive a provably-correct human-robot collaboration design theory that can guarantee the accomplishment of high-level complex missions. Research from this project can benefit society by increasing the safety and trustworthiness in the many real-world applications involving human-robot and human-computer collaborations such as service robots, automated manufacturing systems, emergency responses, and exploration of unknown spaces.&lt;br/&gt;&lt;br/&gt;This project adopts a new model, called vector auto-regressive partially observable Markov decision process (VAR-POMDP), to manage uncertainties, and it uses non-parametric Bayesian methods to learn the model from data. With the learned model, an automatic high-level task planning in human-robot collaboration with respect to formal specifications is studied. The team of researchers will further study how to achieve online (real-time) adaptations of the overall system when robots are interacting with different individuals or facing uncertain environments. Beyond theoretical studies, the team will develop software tools and evaluate the effectiveness of the design theory through a real robotic test-bed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/20/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2007949</AwardID>
<Investigator>
<FirstName>Hai</FirstName>
<LastName>Lin</LastName>
<EmailAddress>hlin1@nd.edu</EmailAddress>
<StartDate>08/20/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Notre Dame</Name>
<CityName>NOTRE DAME</CityName>
<ZipCode>465565708</ZipCode>
<PhoneNumber>5746317432</PhoneNumber>
<StreetAddress>940 Grace Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
</Appropriation>
</Award>
</rootTag>
