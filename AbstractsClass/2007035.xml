<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Scaling up Robot Learning by Understanding Internet Videos</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>460000.00</AwardTotalIntnAmount>
<AwardAmount>460000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Even simple common sense knowledge (for example, that drawers can be opened by pulling on handles, or how to efficiently find the way to a coffee shop in a new hotel without a map) is hard to incorporate into control algorithms in an automated manner at scale. Incorporating such knowledge in the form of hand-designed rules leads to brittle systems and does not scale. This necessitates the use of machine learning to automatically learn such knowledge from data. Current machine learning techniques largely learn by discovering this knowledge by themselves via trial-and-eror. Not only is this computationally expensive, but it also results in specialized behavior that does not generalize to new operating conditions. This makes it challenging and tedious to deploy such learned control algorithms. At the same time, such world knowledge is readily depicted in datasets of first and third-person videos of people conducting different tasks found on the Internet. This project will advance the state-of-the-art by developing techniques to extract knowledge from such videos, to aid learning of decision making and control algorithms. Techniques developed in this project will enable easier, faster, and better training of robots (such as in automated manufacturing). This will enable broader adoption of learned policies for basic navigation and manipulation tasks in previously unseen environments. Effective policies for basic robotic tasks will aid future robotics research on higher-level problems (such as task planning, and human-robot interaction), and computer vision research on interactive problems (like active learning and active perception). The project will also contribute to the education of graduate and undergraduate students by the development of specialized courses and involvement in research, and the research community at large through accessible dissemination of research. &lt;br/&gt;&lt;br/&gt;In order to learn robot policies from Internet videos, the project will develop a framework that leverages the synergies between learning via direct interaction and large-scale video understanding, to learn from and for each other. Researchers will develop video understanding techniques that allow a) building representations that are sensitive to object states, b) acquiring skills for short-range navigation and manipulation, and c) learning value functions that encode world knowledge for task completion. Collectively, these will enable sample efficient learning of control policies that generalize well. Researchers will collect and curate relevant datasets. These datasets will be processed to make them amenable for learning useful policies and representations, by aligning relevant videos in space and time, and grounding transitions into actions. Useful representations for policy learning will be extracted by learning state-sensitive features, parameterized skills, and value functions that capture knowledge about the world. The effectiveness of the proposed framework will be demonstrated through faster learning and better generalization of learned behaviors as compared to existing approaches.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/23/2020</MinAmdLetterDate>
<MaxAmdLetterDate>07/23/2020</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2007035</AwardID>
<Investigator>
<FirstName>Saurabh</FirstName>
<LastName>Gupta</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Saurabh Gupta</PI_FULL_NAME>
<EmailAddress>saurabhg@illinois.edu</EmailAddress>
<PI_PHON>5107595295</PI_PHON>
<NSF_ID>000814888</NSF_ID>
<StartDate>07/23/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Illinois at Urbana-Champaign</Name>
<CityName>Champaign</CityName>
<CountyName>CHAMPAIGN</CountyName>
<ZipCode>618207406</ZipCode>
<PhoneNumber>2173332187</PhoneNumber>
<StreetAddress>1901 South First Street</StreetAddress>
<StreetAddress2><![CDATA[Suite A]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<StateCode>IL</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>IL13</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>041544081</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF ILLINOIS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>041544081</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Illinois at Urbana-Champaign]]></Name>
<CityName>Urbana</CityName>
<CountyName>CHAMPAIGN</CountyName>
<StateCode>IL</StateCode>
<ZipCode>618013620</ZipCode>
<StreetAddress><![CDATA[506 S. Wright Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Illinois</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>IL13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2020~460000</FUND_OBLG>
</Award>
</rootTag>
