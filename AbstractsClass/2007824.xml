<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: RUI: Creation of Assistive Technology for the Blind Through Largescale Co-Design</AwardTitle>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>343842.00</AwardTotalIntnAmount>
<AwardAmount>343842</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
</ProgramOfficer>
<AbstractNarration>People who are blind face significant challenges, including a heightened risk of depression and a rate of participation in the labor force less than half that of the general population.  Among other factors, difficulties with orientation and mobility (O&amp;M) play a key role in the challenges faced by members of this community.  Engineers have long tried to use technology to assist with O&amp;M, but despite many attempts the impact of these efforts has been modest.  This mixed track record is due to both shortcomings in technology (e.g., expensive yet unreliable hardware) as well as in methodology (e.g., not useful to a broad sample of users).  While each of these shortcomings could be addressed in isolation, they can be most effectively addressed together.  To this end, this project will create an infrastructure to enable two novel capabilities: designing O&amp;M technology with people all around the world; and creating O&amp;M technology with state-of-the-art flexibility and accuracy.  These capabilities will be based on smartphones, which have recently been updated with 3D-sensing algorithms to support augmented reality; while these features were primarily designed to support experiences for sighted people, they have the potential to be repurposed as a robust platform for O&amp;M technology.  Project outcomes will provide enhanced support for independence and job-readiness for the eight million Americans who are blind.  Additional broad impacts will derive from educational and outreach activities, including a summer research experience for 18 undergraduates at least 3 of whom will be blind, and a course on assistive technology and user-centered design where undergraduates will work directly with people in the community to improve accessibility.&lt;br/&gt;&lt;br/&gt;To achieve its objectives, the project will create a data-driven design process to allow a large, distributed team to work together to build O&amp;M technology, ultimately recruiting dozens of co-designers (both blind and sighted) towards the goal of creating systems that are state-of-the-art in their robustness and usability.  To recruit a large team of co-designers, the project will leverage the user base of the Clew smartphone app for O&amp;M, which is used by 1,000 unique users per month.  Smartphone-based features for O&amp;M assistive technology will be evaluated, providing narrative feedback coupled with rich data streams utilizing a smartphone's sensors.  The collected sensor data will be processed using novel machine learning and crowdsourcing algorithms to extract information (e.g., the user's location and the location of nearby objects), creating a first-of-its-kind dataset.  The project will train machine learning algorithms on this dataset to create layers of functionality on top of the AR features of smartphones, to enable advanced capabilities such as the diagnosis and repair of motion-tracking errors.  The project team will collaborate with people who are blind to incorporate these new capabilities into Clew, advancing the state-of-the-art in indoor navigation and exploration technology.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/19/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2007824</AwardID>
<Investigator>
<FirstName>Paul</FirstName>
<LastName>Ruvolo</LastName>
<EmailAddress>Paul.Ruvolo@olin.edu</EmailAddress>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Franklin W. Olin College of Engineering</Name>
<CityName>Needham</CityName>
<ZipCode>024921200</ZipCode>
<PhoneNumber>7812922426</PhoneNumber>
<StreetAddress>1000 Olin Way</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>9229</Code>
<Text>RES IN UNDERGRAD INST-RESEARCH</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
</Appropriation>
</Award>
</rootTag>
