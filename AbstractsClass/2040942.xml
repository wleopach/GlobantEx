<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>FAI: Organizing Crowd Audits to Detect Bias in Machine Learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2021</AwardEffectiveDate>
<AwardExpirationDate>01/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>625000.00</AwardTotalIntnAmount>
<AwardAmount>625000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Machine learning development teams often struggle to detect and mitigate harmful stereotypes due to their own blind spots, particularly when ML systems are deployed globally. These kinds of representation harms cannot be easily quantified using today’s automated techniques or fairness metrics, and require knowledge of specific social, cultural, and historical contexts. The researchers team will develop a crowd audit service that harnesses the power of volunteers and crowd workers to identify specific cases of bias and unfairness in machine learning systems, generalize those to systematic failures, and synthesize and prioritize these findings in a form that is readily actionable by development teams. Success in the research team’s work will lead to new ways to identify bias and unfairness in machine learning systems, thus improving trust and reliability in these systems. The research team’s work will be shared through a public web site that will make it easy for journalists, policy makers, researchers, and the public at large to engage in understanding algorithmic bias as well as participating in finding unfair behaviors in machine learning systems. &lt;br/&gt;&lt;br/&gt;This project will explore three major research questions. The first is investigating new techniques for recruiting and incentivizing participation from a diverse crowd. The second is developing new and effective forms of guidance for crowd workers for finding instances and generalizing instances of bias. The third is designing new ways of synthesizing findings from the crowd so that development teams can understand and productively act on. The outputs of this research will include developing a taxonomy of harms; designing and evaluating new kinds of tools to help the crowd tag, discuss, and generalize representation harms; synthesizing new design practices in algorithmic socio-technical platforms in which these platforms can provide users with the opportunity to identify and report observed unfair system behaviors via the platform itself; and gathering new data sets consisting of unfair ML system behaviors identified by the crowd. These datasets will support future research into the design of crowd auditing systems, the nature of representation harms in ML systems, and for future ML teams working on similar kinds of systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/25/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2040942</AwardID>
<Investigator>
<FirstName>Jason</FirstName>
<LastName>Hong</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Jason Hong</PI_FULL_NAME>
<EmailAddress>jasonh@cs.cmu.edu</EmailAddress>
<PI_PHON>4122681295</PI_PHON>
<NSF_ID>000255506</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Nihar</FirstName>
<LastName>Shah</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Nihar Shah</PI_FULL_NAME>
<EmailAddress>nihars@andrew.cmu.edu</EmailAddress>
<PI_PHON/>
<NSF_ID>000753892</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Adam</FirstName>
<LastName>Perer</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Adam Perer</PI_FULL_NAME>
<EmailAddress>adamperer@cmu.edu</EmailAddress>
<PI_PHON>4122682087</PI_PHON>
<NSF_ID>000793964</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kenneth</FirstName>
<LastName>Holstein</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kenneth J Holstein</PI_FULL_NAME>
<EmailAddress>kjholste@cs.cmu.edu</EmailAddress>
<PI_PHON>4129830168</PI_PHON>
<NSF_ID>000818904</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Motahhare</FirstName>
<LastName>Eslami</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Motahhare Eslami</PI_FULL_NAME>
<EmailAddress>meslami@andrew.cmu.edu</EmailAddress>
<PI_PHON>2174184929</PI_PHON>
<NSF_ID>000832693</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<StreetAddress2><![CDATA[WQED Building]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA18</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>052184116</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>CARNEGIE MELLON UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>052184116</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Carnegie Mellon University]]></Name>
<CityName>Pittsburgh</CityName>
<StateCode>PA</StateCode>
<ZipCode>152133890</ZipCode>
<StreetAddress><![CDATA[5000 Forbes Ave WQED Building]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>18</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA18</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>114Y</Code>
<Text>Fairness in Artificial Intelli</Text>
</ProgramElement>
<ProgramReference>
<Code>0757</Code>
<Text>COOP PLAN OPs &amp; SERVICES</Text>
</ProgramReference>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~625000</FUND_OBLG>
</Award>
</rootTag>
