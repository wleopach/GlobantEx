<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Robust Perception and Customization for Long-Term Autonomous Mobile Service Robots</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2021</AwardEffectiveDate>
<AwardExpirationDate>03/31/2026</AwardExpirationDate>
<AwardTotalIntnAmount>590469.00</AwardTotalIntnAmount>
<AwardAmount>590469</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Siddiq Qidwai</SignBlockName>
<PO_EMAI>sqidwai@nsf.gov</PO_EMAI>
<PO_PHON>7032922211</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This Faculty Early Career Development (CAREER) award will enable mobile service robots capable of operating in real-world human environments over extended periods of time. Existing approaches in robot perception are very good at reasoning about the current state of the world but suffer from a marked limitation in reasoning about potential changes that inevitably occur over time. Another common problem of robot perception is that when deployed in unforeseen environments, robots commonly experience perception failures due to unanticipated conditions and violations of design assumptions. Finally, end-use customization and enhancements during operational use is tedious and fragile. This project will overcome these challenges by developing robust algorithmic approaches to recognize and react to dynamic changes in environment, identify failures in perception and learn from them, and additionally learn new tasks while in operation. The research will enable the development and long-term deployment of mobile service robots in homes, workplaces, disaster zones, hospitals, and myriad other environments. As part of the project, the education and outreach plan will include a longitudinal effort for the education and mentoring of undergraduate students throughout the academic year as well as computing workshops with fun robotic activities for middle to high school students.&lt;br/&gt;&lt;br/&gt;This objective of this project is to develop robust algorithmic formulations and analytical and symbolic models to enable long-duration autonomous mobile operations of service robots in dynamic human environments. First, a reformulation of robot perception will be introduced that will explicitly reason about the relation between the current state of the world and possible changes over time, in terms of the geometric shapes, visual appearances, and types of motions that objects are likely to exhibit in the world. Second, approaches will be developed for robots to autonomously build models of their perception competence by leveraging redundant sensing and discrepancies between perceptual predictions and actual outcomes, thus enabling them to avoid or overcome future situations that would lead to errors. Finally, techniques will be developed to address customizability and learning of novel tasks using physics-inspired symbolic programs. The approaches developed will be rigorously tested at multiple levels of integration, including on a team of autonomous mobile service robots deployed indoors and outdoors, performing tasks including package delivery, guided tours, and environment monitoring.&lt;br/&gt;&lt;br/&gt;This project is supported by the cross-directorate Foundational Research in Robotics program, jointly managed and funded by the Directorates for Engineering (ENG) and Computer and Information Science and Engineering (CISE).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/23/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2046955</AwardID>
<Investigator>
<FirstName>Joydeep</FirstName>
<LastName>Biswas</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joydeep Biswas</PI_FULL_NAME>
<EmailAddress>joydeepb@cs.utexas.edu</EmailAddress>
<PI_PHON>4126260553</PI_PHON>
<NSF_ID>000702936</NSF_ID>
<StartDate>03/23/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
<CONGRESSDISTRICT>10</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>TX10</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>170230239</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF TEXAS AT AUSTIN</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042000273</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Texas at Austin]]></Name>
<CityName>Austin</CityName>
<StateCode>TX</StateCode>
<ZipCode>787121757</ZipCode>
<StreetAddress><![CDATA[2317 Speedway, Stop D9500]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>TX25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1045</Code>
<Text>CAREER: FACULTY EARLY CAR DEV</Text>
</ProgramElement>
<ProgramElement>
<Code>144Y</Code>
<Text>FRR-Foundationl Rsrch Robotics</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>6840</Code>
<Text>ROBOTICS</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~590469</FUND_OBLG>
</Award>
</rootTag>
