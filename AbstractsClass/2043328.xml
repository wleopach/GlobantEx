<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Emergent motor timing influences perceptual learning</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2021</AwardEffectiveDate>
<AwardExpirationDate>08/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>388701.00</AwardTotalIntnAmount>
<AwardAmount>388701</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Many real-world behaviors, such as tapping to a musical beat, throwing a ball, or crossing the street, depend on precise timing among perception, cognition, and motor action. Luckily, our motor systems usually operate seamlessly in concert with our perceptual and cognitive processes. Despite how they work together in the real world, these aspects of behavior have been largely studied separately in the laboratory. While that approach allows scientific rigor and has provided significant insights into each subsystem, it says little about their interaction, which may be fundamental to understanding human behavior. A better understanding of how the temporal aspects of perceptual, cognitive, and motor behaviors are interrelated also has the potential to advance technological innovations, e.g., in cognitive neural prosthetics, a novel human-computer interface for helping paralyzed patients and patients with amputations. Identifying the temporal interactions among cognitive, perceptual, and motor functions has other translational potential for developing new rehabilitation paradigms for populations with impaired motor and perceptual timing. &lt;br/&gt;&lt;br/&gt;This research program aims to evaluate whether and how timing in perception and motor control involves shared mechanisms that ensure seamless integration and plastic co-modification. The experimental approach combines a motor skill, throwing a ball in an augmented reality environment, with a time perception task. Objective 1 explores how motor timing that emerges from discrete throwing actions modifies perceptual timing. Objective 2 extends this question to situations requiring rhythmic throwing actions. Objective 3 examines whether learned coupling of motor and perceptual timing persists in the longer term. Taken together, this quantitative approach to understanding the connections between perceptual and motor timing will contribute to developing a unified theory of timing control in real-world contexts. The female investigator team has also identified multiple outreach activities to foster and communicate the integration of scientific research and STEM education and to increase minority representation in the cognitive, perceptual, and motor sciences.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/01/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2043328</AwardID>
<Investigator>
<FirstName>Joo-Hyun</FirstName>
<LastName>Song</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Joo-Hyun Song</PI_FULL_NAME>
<EmailAddress>Joo-Hyun_Song@brown.edu</EmailAddress>
<PI_PHON>4018637666</PI_PHON>
<NSF_ID>000599780</NSF_ID>
<StartDate>04/01/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Brown University</Name>
<CityName>Providence</CityName>
<ZipCode>029129002</ZipCode>
<PhoneNumber>4018632777</PhoneNumber>
<StreetAddress>BOX 1929</StreetAddress>
<StreetAddress2><![CDATA[350 Eddy Street]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<StateCode>RI</StateCode>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>RI01</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>001785542</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>BROWN UNIVERSITY IN PROVIDENCE IN THE STATE OF RHODE ISLAND AND PROVIDENCE PLANTATIONS</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>001785542</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Brown University]]></Name>
<CityName>Providence</CityName>
<StateCode>RI</StateCode>
<ZipCode>029129002</ZipCode>
<StreetAddress><![CDATA[350 Eddy Street]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Rhode Island</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>01</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>RI01</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>058Y</Code>
<Text>M3X - Mind, Machine, and Motor</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>070E</Code>
<Text>INTEG OF HUMAN &amp; COGNITIVE</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>7632</Code>
<Text>HUMAN-ROBOT INTERACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~388701</FUND_OBLG>
</Award>
</rootTag>
