<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: MLWiNS: Physical Layer Communication revisited via  Deep Learning</AwardTitle>
<AwardEffectiveDate>08/01/2020</AwardEffectiveDate>
<AwardExpirationDate>07/31/2023</AwardExpirationDate>
<AwardTotalIntnAmount>223334.00</AwardTotalIntnAmount>
<AwardAmount>223334</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Phillip Regalia</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Reliable communication is a workhorse of the modern information age. The disciplines of communication, coding, and information theory drive the innovation by designing efficient codes that allow transmissions to be robustly decoded. Progress in near optimal codes is made by individual human ingenuity and breakthroughs have been, befittingly, sporadic, spread over several decades. Deep learning has recently shown strong promise in problems where the space of algorithmic choices is enormous (e.g., Go). This scenario likewise characterizes communication theory. Deep learning methods can play a crucial role in achieving the aforementioned goals. All resulting algorithms will be maintained on an online repository with full source code and documentation. The practical applications of the new codes will be explored in the context of wireless deployments. The research outcomes will be used to develop new undergraduate and graduate curricula. &lt;br/&gt; &lt;br/&gt;The fundamental nature of the research spans two areas of independent scientific and technical interest: finite block length information theory and the mathematics of deep learning. This project aims to bring the tools of deep learning to design a new family of encoding and decoding methods for canonical communication models; the codes so generated are naturally built for finite block lengths. In parallel, the viewpoint of neural network architectures as encoding and decoding procedures provides a unique vantage point to study their mathematical properties.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>05/18/2020</MinAmdLetterDate>
<MaxAmdLetterDate>05/18/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2002664</AwardID>
<Investigator>
<FirstName>Sewoong</FirstName>
<LastName>Oh</LastName>
<EmailAddress>sewoong@cs.washington.edu</EmailAddress>
<StartDate>05/18/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
</Institution>
<ProgramElement>
<Code>1714</Code>
<Text>Special Projects - CNS</Text>
</ProgramElement>
<ProgramReference>
<Code>021Z</Code>
<Text>Industry Partnerships</Text>
</ProgramReference>
<ProgramReference>
<Code>8585</Code>
<Text>NSF/Intel Partnership Projects</Text>
</ProgramReference>
</Award>
</rootTag>
