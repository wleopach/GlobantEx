<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>FAI: Measuring and Mitigating Biases in Generic Image Representations</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>02/01/2021</AwardEffectiveDate>
<AwardExpirationDate>01/31/2024</AwardExpirationDate>
<AwardTotalIntnAmount>375000.00</AwardTotalIntnAmount>
<AwardAmount>375000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032928930</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Visual recognition is a remarkable task performed by the human brain. Computational methods trained to emulate this capability rely on observing millions of examples of visual input paired with human annotations. These computational methods have made great progress and are being increasingly adopted in many user-facing applications such as image search, automated image tagging, semi-autonomous navigation systems, smart virtual assistants, etc. However, the underlying visual recognition models in these systems often produce errors by associating sensitive variables of societal significance with their predictions. The goal of this project is to measure and mitigate such errors in a systematic fashion. For example, if a method is able to recognize images of scenes such as 'classroom', the goal of this project is to ensure that such predictions are obtained based on cues such as the presence of a whiteboard, chairs, desks, and other elements typically needed for a space to function as a classroom and not based on incidental elements such as the characteristics or attributes of people present in the classroom. To this end, this project aims to make it easier to determine to what extent methods for computational visual recognition rely on spurious associations with incidental elements.&lt;br/&gt;&lt;br/&gt;This project will provide a study of societal biases present in current methods and models for computational visual recognition that are widely used as a source of generic visual representations. The developed methods will be based on solid foundations drawn from both the machine learning, computer vision, and software testing communities. The project introduces association tests to probe models trained under a variety of conditions to systematically disentangle the biases introduced during generic visual representation learning. The project will be 1) developing a general assessment methodology to measure various types of biases in generic visual representation learning, 2) proposing methods to diminish the impact of these biases in existing generic visual representation extraction models, and 3) measuring the impact of these biases on some key downstream tasks. These three research aims will be complemented by a comprehensive evaluation plan and broadening participation activities. This research effort will bring novel insights into the sources of biases in the predictions of computer vision models and methodologies to make informed decisions about the risks in the deployment of such models.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>01/25/2021</MinAmdLetterDate>
<MaxAmdLetterDate>05/20/2021</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2040961</AwardID>
<Investigator>
<FirstName>Baishakhi</FirstName>
<LastName>Ray</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Baishakhi Ray</PI_FULL_NAME>
<EmailAddress>rayb@cs.columbia.edu</EmailAddress>
<PI_PHON>3037482958</PI_PHON>
<NSF_ID>000701468</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Vicente</FirstName>
<LastName>Ordonez</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Vicente Ordonez</PI_FULL_NAME>
<EmailAddress>vo2m@virginia.edu</EmailAddress>
<PI_PHON>4349822225</PI_PHON>
<NSF_ID>000727654</NSF_ID>
<StartDate>01/25/2021</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Virginia Main Campus</Name>
<CityName>CHARLOTTESVILLE</CityName>
<ZipCode>229044195</ZipCode>
<PhoneNumber>4349244270</PhoneNumber>
<StreetAddress>P.O.  BOX 400195</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<StateCode>VA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>VA05</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>065391526</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RECTOR &amp; VISITORS OF THE UNIVERSITY OF VIRGINIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>065391526</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Virginia]]></Name>
<CityName>Charlottesville</CityName>
<StateCode>VA</StateCode>
<ZipCode>229041000</ZipCode>
<StreetAddress><![CDATA[85 Engineer's Way, Rice Hall 310]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Virginia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>VA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>114Y</Code>
<Text>Fairness in Artificial Intelli</Text>
</ProgramElement>
<ProgramReference>
<Code>0757</Code>
<Text>COOP PLAN OPs &amp; SERVICES</Text>
</ProgramReference>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<Appropriation>
<Code>0121</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2021~375000</FUND_OBLG>
</Award>
</rootTag>
